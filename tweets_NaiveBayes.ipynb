{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweetlerin veritabanından alınması\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import zemberek\n",
    "import jpype,os\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords \n",
    "durakwords= set(stopwords.words(\"turkish\"))\n",
    "import string\n",
    "import re\n",
    "from typing import List\n",
    "from jpype import JClass, JString, getDefaultJVMPath, shutdownJVM, startJVM, java\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding,SpatialDropout1D,LSTM,Dense\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "%matplotlib inline\n",
    "df=pd.DataFrame()\n",
    "df=pd.read_csv(\"C:/Users/user/tweets/tweets2.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tweetlerin küçük harfe dönüştürülmesi\n",
    "df= df.rename(columns = {'hash,content,class': 'tweets'})\n",
    "df['tweets']=df['tweets'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweetlerin son değerlerine göre yeni bir dataframe e yerleştirilmesi\n",
    "#1 tek,2 spor,eko,pol,mag,sağ,kült\n",
    "#df[df.tweets.str.endswith('2')]\n",
    "df['icerik']='icerik'\n",
    "df['cleantext']='cleantext'\n",
    "df.loc[df['tweets'].str.endswith('1'),'icerik']=\"teknoloji\"\n",
    "df.loc[df['tweets'].str.endswith('2'),'icerik']=\"spor\"\n",
    "df.loc[df['tweets'].str.endswith('3'),'icerik']=\"ekonomi\"\n",
    "df.loc[df['tweets'].str.endswith('4'),'icerik']=\"politika\"\n",
    "df.loc[df['tweets'].str.endswith('5'),'icerik']=\"magazin\"\n",
    "df.loc[df['tweets'].str.endswith('8'),'icerik']=\"kultur\"\n",
    "df.loc[df['tweets'].str.endswith('7'),'icerik']=\"saglik\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zemberek kütüphanesinin kullanılabilmesi için Jpype ile JVM oluşturulması\n",
    "ZEMBEREK_PATH = r'C:\\Users\\user\\Desktop\\dersler\\tweets\\zemberek-full.jar'\n",
    "startJVM(getDefaultJVMPath(), '-ea', '-Djava.class.path=%s' % (ZEMBEREK_PATH))\n",
    "#Morphology kütüphanesini kullanacağımızdan burada oluşturuyoruz\n",
    "TurkishMorphology = JClass('zemberek.morphology.TurkishMorphology')\n",
    "morphology = TurkishMorphology.createWithDefaults()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mentionRemove(text):\n",
    "    text = re.sub(r'@\\w+', '', text)#mentionların çıkartırılması\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def siteRemove(text):\n",
    "    text = re.sub(r'http.?://[^\\s]+[\\s]?', '', text)#bağlantıların çıkarılması\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def puncRemove(text):\n",
    "    text = re.sub('[^a-zığüşiöç\\s]', '', text)#özel karakterlerin ve sayıların çıkarılması\n",
    "    text = re.sub(r\"Â\", \"A\", text)#umlautlu karakterlerinn değiştirilmesi\n",
    "    text = re.sub(r\"â\", \"a\", text)\n",
    "    text = re.sub(r\"Î\", \"I\", text)\n",
    "    text = re.sub(r\"î\", \"ı\", text)\n",
    "    text = re.sub(r\"Û\", \"U\", text)\n",
    "    text = re.sub(r\"û\", \"u\", text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeSw(text):\n",
    "    text=[w for w in tweet if w.lower() not in durakwords]#stopwordlerin çıkarılması\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rootFinder(text):\n",
    "    pos=[]\n",
    "    textlist=text.split(\" \")\n",
    "    analysis: java.util.ArrayList = ( morphology.analyzeAndDisambiguate(text).bestAnalysis() )\n",
    "    for i, analysis in enumerate(analysis, start=1):\n",
    "        f'\\nAnalysis {i}: {analysis}',\n",
    "        f'\\nPrimary POS {i}: {analysis.getPos()}' \n",
    "        if (str(analysis.getLemmas()[0]) == \"UNK\"):\n",
    "            pos.append(textlist[i-1])\n",
    "        else:     \n",
    "            pos.append(f'{str(analysis.getLemmas()[0])}')\n",
    "    return pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emojiRemove(tweet):\n",
    "    # Smile -- :), : ), :-), (:, ( :, (-:, :')\n",
    "    tweet = re.sub(r'(:\\s?\\)|:-\\)|\\(\\s?:|\\(-:|:\\'\\))', ' EMO_POS ', tweet)\n",
    "    # Laugh -- :D, : D, :-D, xD, x-D, XD, X-D\n",
    "    tweet = re.sub(r'(:\\s?D|:-D|x-?D|X-?D)', ' EMO_POS ', tweet)\n",
    "    # Love -- <3, :*\n",
    "    tweet = re.sub(r'(<3|:\\*)', ' EMO_POS ', tweet)\n",
    "    # Wink -- ;-), ;), ;-D, ;D, (;,  (-;\n",
    "    tweet = re.sub(r'(;-?\\)|;-?D|\\(-?;)', ' EMO_POS ', tweet)\n",
    "    # Sad -- :-(, : (, :(, ):, )-:\n",
    "    tweet = re.sub(r'(:\\s?\\(|:-\\(|\\)\\s?:|\\)-:)', ' EMO_NEG ', tweet)\n",
    "    # Cry -- :,(, :'(, :\"(\n",
    "    tweet = re.sub(r'(:,\\(|:\\'\\(|:\"\\()', ' EMO_NEG ', tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hash kısmının ve sondaki içerik belirteci ve tweet bağlantısının kaldırılması\n",
    "#utf-16 karakterlerin elenmesi\n",
    "#kelimelerin ayrıştırılması\n",
    "#tweet içerisindeki bağlantıların çıkarılması\n",
    "#tweet içindeki mentionların çıkarılması\n",
    "p=set(string.punctuation)\n",
    "\n",
    "def cleaner(text):\n",
    "    text=text\n",
    "    text=mentionRemove(text)#mentionların çıkartırılması\n",
    "    text=siteRemove(text)#bağlantıların çıkarılması\n",
    "    text=puncRemove(text)#özel karakterlerin ve sayıların çıkarılması\n",
    "    text=emojiRemove(text)\n",
    "    text=rootFinder(text)#kelime köklerinin bulunması\n",
    "    text=removeSw(text)#durak kelimelerin elenmesi\n",
    "    return text\n",
    "for x in range(0,len(df)):\n",
    "    #tweet=\"ve ya da için baba veya\"\n",
    "    tweet=df.iloc[x,0]\n",
    "    tweet=mentionRemove(tweet)#mentionların çıkartırılması\n",
    "    tweet=siteRemove(tweet)#bağlantıların çıkarılması\n",
    "    #tweet.replace(\"aracılığıyla\",\"a\")\n",
    "    tweet=puncRemove(tweet)#özel karakterlerin ve sayıların çıkarılması\n",
    "    tweet=rootFinder(tweet)#kelime köklerinin bulunması\n",
    "    tweet=removeSw(tweet)#durak kelimelerin elenmesi\n",
    "    tweet=' '.join(tweet)\n",
    "    #tweet=cleaner(tweet)\n",
    "    df.iloc[x,2]=tweet\n",
    "    pos=[]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['ekonomi', 'kultur', 'magazin', 'politika', 'saglik', 'spor', 'teknoloji']\n",
    "plt.figure(figsize=(10,4))\n",
    "df.icerik.value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Naive Bayes With Count Vectorzier\n",
    "#https://github.com/Birinder1469/MultiClass_Text_Classification/blob/master/src/MultiClass_Classification.ipynb\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.iloc[4,0])\n",
    "print(df.iloc[4,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.cleantext\n",
    "Y = df.icerik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_counts=CountVectorizer()\n",
    "x_counts=cv_counts.fit_transform(df.cleantext).toarray()\n",
    "x_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(x_counts, Y, test_size=0.3, random_state = 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_Multinomial=MultinomialNB()\n",
    "clf_Multinomial.fit(X_train,Y_train)\n",
    "print('The Train score for Multinomial is {0}'.format(clf_Multinomial.score(X_train,Y_train)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The Test score for Multinomial is {0}'.format(clf_Multinomial.score(X_test,Y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_Multinomial.predict(cv_counts.transform([\"meral akşener dolar mhp ziyaret\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=clf_Multinomial.predict(X_test)\n",
    "print(\"the accuracy score is \",(accuracy_score(Y_test, preds)*100))\n",
    "acc_NB1=(accuracy_score(Y_test,preds)*1004)\n",
    "print(classification_report(Y_test, preds,target_names=['ekonomi', 'kultur', 'magazin', 'politika', 'saglik', 'spor', 'teknoloji']))\n",
    "cr_NB1=classification_report(Y_test,preds,target_names=['ekonomi', 'kultur', 'magazin', 'politika', 'saglik', 'spor', 'teknoloji'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_NB1=confusion_matrix(Y_test,preds)\n",
    "conf_mat = confusion_matrix(Y_test, preds)\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "sns.heatmap(conf_mat, annot=True, cmap=\"Blues\", fmt='d',\n",
    "            xticklabels={'ekonomi', 'kultur', 'magazin', 'politika', 'saglik', 'spor', 'teknoloji'},\n",
    "            yticklabels={'ekonomi', 'kultur', 'magazin', 'politika', 'saglik', 'spor', 'teknoloji'})\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title(\"CONFUSION MATRIX\\n\", size=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Naive Bayes\n",
    "##with tfidf and countvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_t=CountVectorizer().fit(df.cleantext)\n",
    "bow_tweets=bow_t.transform(df.cleantext)\n",
    "print(bow_tweets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer=TfidfTransformer().fit(bow_tweets)\n",
    "print(tfidf_transformer)\n",
    "tweets_tfidf=tfidf_transformer.transform(bow_tweets)\n",
    "print(tweets_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(tweets_tfidf, df.icerik, test_size=0.3, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=MultinomialNB().fit(X_train,Y_train)\n",
    "preds=model.predict(X_test)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy %s\\n' % (accuracy_score(Y_test,preds)*100))\n",
    "acc_NB2=accuracy_score(Y_test,preds)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_test, preds,target_names=['ekonomi', 'kultur', 'magazin', 'politika', 'saglik', 'spor', 'teknoloji']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_NB2=classification_report(Y_test,preds,target_names=['ekonomi', 'kultur', 'magazin', 'politika', 'saglik', 'spor', 'teknoloji'])\n",
    "cm_NB2=confusion_matrix(Y_test,preds)\n",
    "cf_NB2=conf_mat\n",
    "conf_mat = confusion_matrix(Y_test, preds)\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "sns.heatmap(conf_mat, annot=True, cmap=\"Blues\", fmt='d',\n",
    "            xticklabels={'ekonomi', 'kultur', 'magazin', 'politika', 'saglik', 'spor', 'teknoloji'},\n",
    "            yticklabels={'ekonomi', 'kultur', 'magazin', 'politika', 'saglik', 'spor', 'teknoloji'})\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title(\"CONFUSION MATRIX\\n\", size=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Naive Bayes\n",
    "#with tfidf with pipeline countvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.cleantext\n",
    "y = df.icerik\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = nb.predict(X_test)\n",
    "print('accuracy %s\\n' % (accuracy_score(y_test, y_pred)*100))\n",
    "acc_NB3=accuracy_score(y_test, y_pred)*100\n",
    "print(classification_report(y_test, y_pred,target_names=['ekonomi', 'kultur', 'magazin', 'politika', 'saglik', 'spor', 'teknoloji']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_NB3=classification_report(y_test,y_pred,target_names=['ekonomi', 'kultur', 'magazin', 'politika', 'saglik', 'spor', 'teknoloji'])\n",
    "cm_NB3=confusion_matrix(y_test,y_pred)\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "sns.heatmap(conf_mat, annot=True, cmap=\"Blues\", fmt='d',\n",
    "            xticklabels={'ekonomi', 'kultur', 'magazin', 'politika', 'saglik', 'spor', 'teknoloji'},\n",
    "            yticklabels={'ekonomi', 'kultur', 'magazin', 'politika', 'saglik', 'spor', 'teknoloji'})\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title(\"CONFUSION MATRIX\\n\", size=16);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Naive bayes with svm and tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(df['cleantext'],df['icerik'],test_size=0.3,random_state=44)\n",
    "Train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier - Algorithm - Naive Bayes\n",
    "# fit the training dataset on the classifier\n",
    "Encoder = LabelEncoder()\n",
    "Train_Y = Encoder.fit_transform(Train_Y)\n",
    "Test_Y = Encoder.fit_transform(Test_Y)\n",
    "Tfidf_vect = TfidfVectorizer(max_features=10000)\n",
    "Tfidf_vect.fit(df['cleantext'])\n",
    "Train_X_Tfidf = Tfidf_vect.transform(Train_X)\n",
    "Test_X_Tfidf = Tfidf_vect.transform(Test_X)\n",
    "Naive = naive_bayes.MultinomialNB()\n",
    "Naive.fit(Train_X_Tfidf,Train_Y)\n",
    "predictions_NB = Naive.predict(Test_X_Tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"NB Accuracy Score -> \",accuracy_score(Test_Y,predictions_NB)*100)\n",
    "print(classification_report(Test_Y,predictions_NB,target_names=['ekonomi', 'kultur', 'magazin', 'politika', 'saglik', 'spor', 'teknoloji']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier - Algorithm - SVM\n",
    "# fit the training dataset on the classifier\n",
    "SVM = svm.SVC(C=1.0, kernel='linear', gamma='auto')\n",
    "SVM=SVM.fit(Train_X_Tfidf,Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the labels on validation dataset\n",
    "predictions_SVM = SVM.predict(Test_X_Tfidf)\n",
    "\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, Test_Y)*100)\n",
    "acc_NB4=accuracy_score(predictions_SVM, Test_Y)*100\n",
    "print(classification_report(predictions_SVM, Test_Y,target_names=['ekonomi', 'kultur', 'magazin', 'politika', 'saglik', 'spor', 'teknoloji']))\n",
    "cr_NB4=classification_report(predictions_SVM, Test_Y,target_names=['ekonomi', 'kultur', 'magazin', 'politika', 'saglik', 'spor', 'teknoloji'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(Test_Y, predictions_SVM)\n",
    "cm_NB4=confusion_matrix(Test_Y,predictions_SVM)\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "sns.heatmap(conf_mat, annot=True, cmap=\"Blues\", fmt='d',\n",
    "            xticklabels={'ekonomi', 'kultur', 'magazin', 'politika', 'saglik', 'spor', 'teknoloji'},\n",
    "            yticklabels={'ekonomi', 'kultur', 'magazin', 'politika', 'saglik', 'spor', 'teknoloji'})\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title(\"CONFUSION MATRIX\\n\", size=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##NB1 Results\n",
    "print(acc_NB1)\n",
    "print(cr_NB1)\n",
    "conf_mat=cm_NB1\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "sns.heatmap(conf_mat, annot=True, cmap=\"Blues\", fmt='d',\n",
    "            xticklabels={'ekonomi', 'kultur', 'magazin', 'politika', 'saglik', 'spor', 'teknoloji'},\n",
    "            yticklabels={'ekonomi', 'kultur', 'magazin', 'politika', 'saglik', 'spor', 'teknoloji'})\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title(\"CONFUSION MATRIX\\n\", size=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc_NB2)\n",
    "print(cr_NB2)\n",
    "conf_mat=cm_NB2\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "sns.heatmap(conf_mat, annot=True, cmap=\"Blues\", fmt='d',\n",
    "            xticklabels={'ekonomi', 'kultur', 'magazin', 'politika', 'saglik', 'spor', 'teknoloji'},\n",
    "            yticklabels={'ekonomi', 'kultur', 'magazin', 'politika', 'saglik', 'spor', 'teknoloji'})\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title(\"CONFUSION MATRIX\\n\", size=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc_NB3)\n",
    "print(cr_NB3)\n",
    "conf_mat=cm_NB3\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "sns.heatmap(conf_mat, annot=True, cmap=\"Blues\", fmt='d',\n",
    "            xticklabels={'ekonomi', 'kultur', 'magazin', 'politika', 'saglik', 'spor', 'teknoloji'},\n",
    "            yticklabels={'ekonomi', 'kultur', 'magazin', 'politika', 'saglik', 'spor', 'teknoloji'})\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title(\"CONFUSION MATRIX\\n\", size=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc_NB4)\n",
    "print(cr_NB4)\n",
    "conf_mat=cm_NB4\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "sns.heatmap(conf_mat, annot=True, cmap=\"Blues\", fmt='d',\n",
    "            xticklabels={'ekonomi', 'kultur', 'magazin', 'politika', 'saglik', 'spor', 'teknoloji'},\n",
    "            yticklabels={'ekonomi', 'kultur', 'magazin', 'politika', 'saglik', 'spor', 'teknoloji'})\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title(\"CONFUSION MATRIX\\n\", size=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
